{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Brexit Logistic regression and decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brexit\n",
    "\n",
    "On June 23rd, 2016, The UK had a national referendum to decide whether the country should leave the\n",
    "EU (‘Brexit’). The result, a win for the Leave campaign, surprised many political commentators, who had\n",
    "expected that people would vote to Remain. Immediately people began to look for patterns that coud explain\n",
    "the Leave vote: cities had generally voted to Remain, while small towns had voted to Leave. England and\n",
    "Wales voted to Leave, while Northern Ireland and especially Scotland voted to Remain.\n",
    "\n",
    "\n",
    "In the next few days, the Guardian newspaper presented some apparent demographic trends in the vote, based\n",
    "on the ages, incomes, education and class of different electoral wards (https://www.theguardian.com/politics/\n",
    "ng-interactive/2016/jun/23/eu-referendum-live-results-and-analysis). The Guardian’s analysis stopped at\n",
    "showing these results graphically, and commenting on the apparent patterns. We will go one better by doing\n",
    "some real statistical analysis of the data.\n",
    "\n",
    "I have scraped the data from the Guardian’s plots into a data file (brexit.csv) which you can download from\n",
    "MINERVA\n",
    "\n",
    "There are 6 attributes in the data. The 5 possible input variables are:\n",
    "\n",
    "* abc1: proportion of individuals who are in the ABC1 social classes (middle to upper class)\n",
    "* medianIncome: the median income of all residents\n",
    "* medianAge: median age of residents\n",
    "* withHigherEd: proportion of residents with any university-level education\n",
    "* notBornUK: the proportion of residents who were born outside the UK\n",
    "\n",
    "These are normalised so that the lowest value is zero and the highest value is one.\n",
    "The output variable is called voteBrexit, and gives a TRUE/FALSE answer to the question ‘did this electoral\n",
    "ward vote for Brexit?’ (i.e. did more than 50% of people vote to Leave?).\n",
    "\n",
    "Tasks (week 6):\n",
    "\n",
    "1. Fit a logistic regression models using all of the available inputs. Identify the direction of each effect\n",
    "from the fitted coefficients. Compare these with the plots shown on the Guardian website. Do they\n",
    "agree?\n",
    "2. Present the value of each coefficient estimate with a 95% confidence interval. Which input would you\n",
    "say has the strongest effect?\n",
    "3. Using aic, perform a model selection to determine which factors are useful to predict the result of\n",
    "the vote. Use a ‘greedy’ input selection procedure, as follows: (i) select the best model with 1 input;\n",
    "(ii) fixing that input, select the best two-input model (i.e. try all the other 4 inputs with the one you\n",
    "selected first); (iii) select the best three-input model containing the first two inputs you chose, etc. At\n",
    "each stage evaluate the quality of fit using aic and stop if this gets worse.\n",
    "\n",
    "Tasks (week 7):\n",
    "\n",
    "1. Use the Scikit-Learn package to create a decision tree classification model. Visualise your model and intepret\n",
    "the fitted model.\n",
    "2. Compare your decision tree model and your logistic regression model. Do they attribute high importance\n",
    "to the same factors? How do you intepret each model to explain the referendum vote?\n",
    "3. Which model would you use if you were explaining the results for a newspaper article, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Fit a logistic regression models using all of the available inputs. Identify the direction of each effect from the fitted coefficients. Compare these with the plots shown on the Guardian website. Do they agree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y        x1        x2        x3        x4        x5\n",
      "0  1  0.133641  0.012605  0.252577  0.500000  0.085526\n",
      "1  1  0.129032  0.113445  0.108247  0.272727  0.111842\n",
      "2  1  0.161290  0.004202  0.128866  0.636364  0.118421\n",
      "3  1  0.322581  0.046218  0.226804  0.454545  0.217105\n",
      "4  1  0.345622  0.058824  0.201031  0.545455  0.243421\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  344\n",
      "Model:                            GLM   Df Residuals:                      338\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -123.69\n",
      "Date:                Fri, 01 Apr 2022   Deviance:                       247.39\n",
      "Time:                        05:55:56   Pearson chi2:                     401.\n",
      "No. Iterations:                     6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.1386      0.848     -0.164      0.870      -1.800       1.523\n",
      "x1            17.5780      2.911      6.038      0.000      11.872      23.284\n",
      "x2             5.6861      1.803      3.153      0.002       2.152       9.221\n",
      "x3            -6.3857      1.922     -3.323      0.001     -10.152      -2.619\n",
      "x4             5.9209      1.407      4.209      0.000       3.164       8.678\n",
      "x5           -26.7443      3.576     -7.478      0.000     -33.753     -19.735\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "# read csv file and set y as output and x's as inputs \n",
    "brexit=pd.read_csv(\"brexit.csv\")\n",
    "y=brexit.voteBrexit*1 # set the TRUE elements in the column to 1 and FALSE elements to 0 as if this isn't transformed the linear regression coefiicients have a change of sign for each input.\n",
    "x1=brexit.abc1\n",
    "x2=brexit.notBornUK\n",
    "x3=brexit.medianIncome\n",
    "x4=brexit.medianAge\n",
    "x5=brexit.withHigherEd\n",
    "\n",
    "\n",
    "#make data frame with all inputs and output\n",
    "df=pd.DataFrame({'y':y,'x1':x1,'x2':x2,'x3':x3,'x4':x4, 'x5':x5})\n",
    "print(df.head())\n",
    "#perform glm with logistic regression model function\n",
    "myglm = glm(' y ~ x1 + x2 + x3 + x4 + x5 ', df, family=sm.families.Binomial()).fit()\n",
    "#print summary\n",
    "print(myglm.summary());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient for 'x1' which represents the proportion of individuals who are in the ABC1 social classes (middle to upper class) is -7.6 (1 decimal point) which shows positive correlation so as as as proportion of individuals who are  in higher social classes increases the more likely they are to vote for Brexit. This is the largest positive  value which indicates that for votes for Brexit people from higher social classes were the most significant voters. This disagrees with the graph on the guardian website as graph shown has a negative correaltion but the maximum and minimum % values of residents of ABC1 social grade, i.e. the values of the y- axis are the largest compared to the other graphs which agrees with the regression model that this input has the large effect on the Brexit vote. The other 2 positive coefficient values were for 'x2' and 'x4' which represent the normal values for median income of residents and proprotion of residents with any university-level education with values of around 5-6 which shows slight positive correlation which disagrees with the graphs about correlation as the graphs show negative correlation. However these factors are not as significant as 'x1' on the graphs too as well as the regression model as the values on the y axis are lower than 'x1'. The input 'x5' representing the input of the proportion of residents who were born outside the UK, has a negtaive coefficient which is the largest value coefficient out of all inputs showing it has the largest effect on the vote and that as this proporition of this input increases the less likely brexit will be voted for which is hown on the graph on the Guardian in both direction and magnitude as a lot of points for leave are close to 0 proprtion and the max values for the y axis is much lower compared to the rest of the graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 \n",
    " Present the value of each coefficient estimate with a 95% confidence interval. Which input would you\n",
    "say has the strongest effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.871724184172496\n",
      "23.284271889057383\n",
      "2.1516688332981717\n",
      "9.22060779588885\n",
      "-10.15220399455139\n",
      "-2.619275270703323\n",
      "3.1640666241245277\n",
      "8.677686874481365\n",
      "-33.753456448683714\n",
      "-19.73506194274948\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "zc = scipy.stats.norm.ppf(0.975)\n",
    "#Extract estimate and standard error of coefficient from model summary (check above)\n",
    "# make for loop so code outputs upper and lower boundaries of confidence intervals for each input\n",
    "# start from 1st to 6th \n",
    "for i in range (1,6,1):\n",
    "    estimate = myglm.params[i]\n",
    "    standard_error = myglm.bse[i]\n",
    "    #Calculate and print the lower and upper boundaries of the confidence interval\n",
    "    CI_min = estimate - zc*standard_error\n",
    "    CI_max = estimate + zc*standard_error\n",
    "    print(CI_min)\n",
    "    print(CI_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence intervals shows that the input of the proportion of residents who were born outside the UK had the largest effect as the absolute values for the min and max are the largest whilst also both beinmg negative so even at the upper boundary of this input the absolute value was at the lowest however still nearly as large as the upper boundary so it is obvious that the proportion of residents who were born outside the UK has the largest effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Using aic, perform a model selection to determine which factors are useful to predict the result of the vote. Use a ‘greedy’ input selection procedure, as follows: (i) select the best model with 1 input; (ii) fixing that input, select the best two-input model (i.e. try all the other 4 inputs with the one you selected first); (iii) select the best three-input model containing the first two inputs you chose, etc. At each stage evaluate the quality of fit using aic and stop if this gets worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) select the best model with 1 input;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AIC value for when proportion of individuals who are in the ABC1 social classes is the only input is 377.543729722669\n",
      "The AIC value for when not born in the UK is the only input is 377.80127885092975\n",
      "The AIC value for median income is the only input is 368.44370373062986\n",
      "The AIC value for when median age is the only input is 401.2766935753845\n",
      "The AIC value for when people with higher education  is the only input is 313.5604055904664\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#make array with all forumlas\n",
    "formula1=['y~x1','y~x2','y~x3','y~x4','y~x5']\n",
    "prints1=[\"The AIC value for when proportion of individuals who are in the ABC1 social classes is the only input is\",\"The AIC value for when not born in the UK is the only input is\",\"The AIC value for median income is the only input is\",\"The AIC value for when median age is the only input is\",\"The AIC value for when people with higher education  is the only input is\"]\n",
    "#make for loop to run all equations with onme input through glm and to print the aic of the glm\n",
    "for (i,j) in zip(formula1,prints1):\n",
    "    my_glm=glm(i,df, family=sm.families.Binomial()).fit()\n",
    "    print(j,my_glm.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model with 1 input is the model where the AIC value is the lowest which is the model where only higher education is the only input Therefore this input will be fixed in part (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AIC value for when proportion of individuals who are in the ABC1 social classes and higher education  are the only input is 286.5454477003765\n",
      "The AIC value for when people not born in the UK and higher education  are the only input is 310.3643998928851\n",
      "The AIC value when median income and higher education  are the only input is 315.5255949327895\n",
      "The AIC value for when median age and higher education  are the only inputs is 303.3090827944477\n"
     ]
    }
   ],
   "source": [
    "# make array with all the forumals with 2 inputs where one of the inputs is fixed from previous part and run for loop so all equations are run through glm\n",
    "formula2=['y~x5+x1','y~x5+x2','y~x5+x3','y~x5+x4']\n",
    "prints2=[\"The AIC value for when proportion of individuals who are in the ABC1 social classes and higher education  are the only input is\",\"The AIC value for when people not born in the UK and higher education  are the only input is\",\"The AIC value when median income and higher education  are the only input is\",\"The AIC value for when median age and higher education  are the only inputs is\"]\n",
    "for (i,j) in zip(formula2,prints2):\n",
    "    my_glm=glm(i,df, family=sm.families.Binomial()).fit()\n",
    "    print(j,my_glm.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model when fixing the best single input and testing the 4 other input as a pair with higher education is when taking proportion of individuals who are in the ABC1 social classes. Now higher eductaion and proportion of individuals who are in the ABC1 social classes will be fixed when testing the bect 3 input models for part (iii)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AIC value for the model when the 3 inputs are higher eduaction,proportion of individuals who are in the ABC1 social classes and not born in the UK is  285.2443784426674\n",
      "The AIC value for the model when the 3 inputs are higher eduaction,proportion of individuals who are in the ABC1 social classes and median income is  275.93391871432317\n",
      "The AIC value for the model when the 3 inputs are higher eduaction,proportion of individuals who are in the ABC1 social classes and median age is 271.93170450949265\n"
     ]
    }
   ],
   "source": [
    "formula3=['y~x5+x1+x2','y~x5+x1+x3','y~x5+x1+x4']\n",
    "prints3=[\"The AIC value for the model when the 3 inputs are higher eduaction,proportion of individuals who are in the ABC1 social classes and not born in the UK is \",\"The AIC value for the model when the 3 inputs are higher eduaction,proportion of individuals who are in the ABC1 social classes and median income is \",\"The AIC value for the model when the 3 inputs are higher eduaction,proportion of individuals who are in the ABC1 social classes and median age is\"]\n",
    "for (i,j) in zip(formula3,prints3):\n",
    "    my_glm=glm(i,df, family=sm.families.Binomial()).fit()\n",
    "    print(j,my_glm.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 'greedy' selection procedure the best 3 input model is when the inputs are  higher education, proportion of individuals who are in the ABC1 soical classed and median age due to the AIC value being the lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Use the Scikit-Learn package to create a decision tree classification model. Visualise your model and intepret\n",
    "the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       abc1  notBornUK  medianIncome  medianAge  withHigherEd\n",
      "0  0.133641   0.012605      0.252577   0.500000      0.085526\n",
      "1  0.129032   0.113445      0.108247   0.272727      0.111842\n",
      "2  0.161290   0.004202      0.128866   0.636364      0.118421\n",
      "3  0.322581   0.046218      0.226804   0.454545      0.217105\n",
      "4  0.345622   0.058824      0.201031   0.545455      0.243421\n",
      "   voteBrexit\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "brexit = pd.read_csv(\"brexit.csv\")\n",
    "voteBrexit=brexit.voteBrexit*1\n",
    "abc1=brexit.abc1\n",
    "notBornUK=brexit.notBornUK\n",
    "medianIncome=brexit.medianIncome\n",
    "medianAge=brexit.medianAge\n",
    "withHigherEd=brexit.withHigherEd\n",
    "# make 2 data frames one containing the inputs callled X and one for the output called Y\n",
    "X=pd.DataFrame({'abc1':abc1,'notBornUK':notBornUK,'medianIncome':medianIncome,'medianAge':medianAge, 'withHigherEd':withHigherEd})\n",
    "print(X.head())\n",
    "Y=pd.DataFrame({'voteBrexit':voteBrexit})\n",
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the decision tree using DecisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# set max depth to 4 as testing other max depths shows 4 has the best balance for \n",
    "mytree1 = DecisionTreeClassifier(max_depth=4)\n",
    "mytree1.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(mytree1,out_file=\"dot_data\",rounded=True,filled=True)\n",
    "!dot -Tpng dot_data -o dot_data.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./dot_data.png\" width=800 alt=\"test\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Compare your decision tree model and your logistic regression model. Do they attribute high importance to the same factors? How do you intepret each model to explain the referendum vote?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model showed that the proportion of residents who were born outside the UK was the most importnat input and the decision tree model does too by making the first node a test on this input. The decision tree does not make the first input which is  the proportion of individuals who are in the ABC1 social classes an important input as the depth of where this test comes into play for this input is further down which doesn't agree with the logistic regression. The other 3 inputs have similiar importance in both the logistic regression and decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Which model would you use if you were explaining the results for a newspaper article, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model I would pick is the logistic regression model as with logistic regression model the coefficients of the model give a clear indication of the coreelation and the magnitude of the impact of each input which also would make it easier to explain and for the readers to understand. You can make a graph using the regression model making the data easier to interpret. While a decision tree although maybe more accurate especially when increasing the depth , it is much harder to show the effect of each input and harder to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Assessment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: 100% of marks awarded\n",
    "Task 2: 100% of marks awarded\n",
    "Task 3: 100% of marks awarded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: 70% of marks awarded\n",
    "Task 2: 50% of marks awarded\n",
    "Task 3: 50% of marks awarded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentation mark: 20 marks out 20\n",
    "Extra marks : 0 out of 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
